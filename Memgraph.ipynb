{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae06d23-c7f2-449b-a5c8-5aa0393090b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "85154020-53f1-4a84-bc63-416138338728",
   "metadata": {},
   "source": [
    "# Memgraph QA\n",
    "\n",
    "This notebook shows how to use LLMS to provide a natural language interface to a Memgraph graph database that you can query with the Cypher query language.\n",
    "\n",
    "You will need to have a running instance of [Memgraph](https://memgraph.com). The easiest option is to create an instance using a Docker container using the following script:\n",
    "\n",
    "docker run \n",
    "    -it -p 7687:7687 \n",
    "    -p 7444:7444 \n",
    "    -p 3000:3000 \n",
    "    -e MEMGRAPH=\"--bolt-server-name-for-init=Neo4j/\" \n",
    "    memgraph/memgraph-platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "98a29f87-700f-485d-a49b-f52c369c777c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import GraphCypherQAChain\n",
    "from langchain.graphs import MemgraphGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c50a3166-de57-40ef-b8fd-2724ff2d582d",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = MemgraphGraph(\n",
    "    url=\"bolt://127.0.0.1:7687\", username=\"username\", password=\"password\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f049a4-0450-437c-8471-a35233eea635",
   "metadata": {},
   "source": [
    "## Seeding the database\n",
    "\n",
    "Using the Datasets section of the menu in [Memgraph Lab](https://memgraph.com/lab), you can choose Load Dataset on the Game of Thrones deaths dataset to easily create a sample database to query. The following code assumes you have loaded this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbef298b-d15f-4880-9c67-94cbe2c593a0",
   "metadata": {},
   "source": [
    "## Refresh graph schema information\n",
    "\n",
    "If the schema of the database changes, you can refresh the schema information need to generate Cypher statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2fdb96fd-df77-4c0d-8d8b-bb0a7ca7ff45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node properties are the following:\n",
      "Node name: 'Character', Node properties: [{'property': 'name', 'type': 'str'}]\n",
      "Node name: 'Location', Node properties: [{'property': 'name', 'type': 'str'}]\n",
      "Node name: 'Allegiance', Node properties: [{'property': 'name', 'type': 'str'}]\n",
      "Node name: 'Episode', Node properties: [{'property': 'number', 'type': 'int'}, {'property': 'name', 'type': 'str'}, {'property': 'imdb_rating', 'type': 'float'}]\n",
      "Node name: 'Season', Node properties: [{'property': 'number', 'type': 'int'}]\n",
      "Node name: 'Death', Node properties: [{'property': 'order', 'type': 'int'}]\n",
      "\n",
      "Relationship properties are the following:\n",
      "Relationship Name: 'KILLED', Relationship Properties: [{'property': 'method', 'type': 'str'}, {'property': 'count', 'type': 'int'}]\n",
      "\n",
      "The relationships are the following:\n",
      "['(:Character)-[:LOYAL_TO]->(:Allegiance)']\n",
      "['(:Character)-[:VICTIM_IN]->(:Death)']\n",
      "['(:Character)-[:KILLER_IN]->(:Death)']\n",
      "['(:Character)-[:KILLED]->(:Character)']\n",
      "['(:Episode)-[:PART_OF]->(:Season)']\n",
      "['(:Death)-[:HAPPENED_IN]->(:Episode)']\n",
      "['(:Death)-[:HAPPENED_IN]->(:Season)']\n",
      "['(:Death)-[:HAPPENED_IN]->(:Location)']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "graph.refresh_schema()\n",
    "print(graph.get_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c87f11c-f421-4173-8647-a91d0b271c44",
   "metadata": {},
   "source": [
    "## Querying the graph\n",
    "\n",
    "We can now use GraphCypherQAChain to ask questions of the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b404545b-f170-4889-98cf-e2ee86067aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = GraphCypherQAChain.from_llm(\n",
    "    ChatOpenAI(temperature=0, model=\"gpt-4\"),\n",
    "    graph=graph,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e4c91ee2-f3e6-4fe1-abc9-04aca48dc5f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mMATCH (c:Character {name: 'Jon Snow'})-[:VICTIM_IN]->(d:Death)-[:HAPPENED_IN]->(l:Location)\n",
      "RETURN l.name\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m[{'l.name': 'Castle Black'}]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "results = chain.run(\"Where did Jon Snow die?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a980321b-d5aa-4968-904d-f4fcce0f5095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jon Snow died at Castle Black.\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5226f75-46c9-4b66-90b5-27d425a889fc",
   "metadata": {},
   "source": [
    "## Limit the number of results\n",
    "\n",
    "You can limit the number of results from the GraphCypherQAChain by using the top_k parameter. The default is 10. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "abbe42de-a72e-4f9f-9fa6-56b1d204e6cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mMATCH (c:Character)-[:LOYAL_TO]->(a:Allegiance)\n",
      "RETURN c.name, COUNT(a) AS allegianceCount\n",
      "ORDER BY allegianceCount DESC\n",
      "LIMIT 1\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m[{'c.name': 'Obara Sand', 'allegianceCount': 2}]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Obara Sand is one of the characters who had the most allegiances, with a count of 2.'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = GraphCypherQAChain.from_llm(\n",
    "    ChatOpenAI(temperature=0), \n",
    "    graph=graph, \n",
    "    verbose=True,\n",
    "    top_k=1\n",
    ")\n",
    "\n",
    "chain.run(\"Which characters had the most allegiances?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca38388-09a3-41d5-90f3-7c58c86d04ad",
   "metadata": {},
   "source": [
    "## Return intermediate results\n",
    "\n",
    "You can return intermediate steps from GraphCypherQAChain using the `return_intermediate_steps` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "50e07983-c3f0-49ff-9604-43a81f502549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mMATCH (c:Character)-[:LOYAL_TO]->(a:Allegiance)\n",
      "WHERE a.name = 'White Walkers'\n",
      "RETURN c.name\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m[{'c.name': 'White Walker'}, {'c.name': 'Viserion'}, {'c.name': 'Wight'}, {'c.name': 'Undead Polar Bear'}, {'c.name': 'Night King'}, {'c.name': 'Giant Wight'}]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Intermediate steps: [{'query': \"MATCH (c:Character)-[:LOYAL_TO]->(a:Allegiance)\\nWHERE a.name = 'White Walkers'\\nRETURN c.name\"}, {'context': [{'c.name': 'White Walker'}, {'c.name': 'Viserion'}, {'c.name': 'Wight'}, {'c.name': 'Undead Polar Bear'}, {'c.name': 'Night King'}, {'c.name': 'Giant Wight'}]}]\n",
      "Final answer: The characters with allegiance to the White Walkers are White Walker, Viserion, Wight, Undead Polar Bear, Night King, and Giant Wight.\n"
     ]
    }
   ],
   "source": [
    "chain = GraphCypherQAChain.from_llm(\n",
    "    ChatOpenAI(temperature=0), \n",
    "    graph=graph, \n",
    "    verbose=True,\n",
    "    return_intermediate_steps=True\n",
    ")\n",
    "\n",
    "results = chain(\"Show me the characters with allegiance to the white walkers.\")\n",
    "print(f\"Intermediate steps: {results['intermediate_steps']}\")\n",
    "print(f\"Final answer: {results['result']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c673c0d-89ff-4a51-868c-eeb5d60bda41",
   "metadata": {},
   "source": [
    "## Return direct results\n",
    "\n",
    "You can return direct results from GraphCypherQAChain using the `return_direct` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f01de355-52df-4944-a934-b1adb3e69fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mMATCH (killer:Character)-[:KILLED]->(victim:Character {name: 'Ned Stark'})\n",
      "RETURN killer.name\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'killer.name': 'Ilyn Payne'}]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = GraphCypherQAChain.from_llm(\n",
    "    ChatOpenAI(temperature=0), \n",
    "    graph=graph, \n",
    "    verbose=True,\n",
    "    return_direct=True\n",
    ")\n",
    "\n",
    "chain.run(\"Who killed Ned Stark?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd74e79-2bf4-4cb4-ac5e-d8c94efd2254",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
